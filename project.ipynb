{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 네이버 쇼핑 리뷰를 보고 판매자 답변 자동 생성하기(정중/사과/보상 제안)",
   "id": "fa64466eca1790b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 데이터 출처 : https://github.com/bab2min/corpus",
   "id": "623f33a35a750969"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. 라이브러리 설치",
   "id": "1c43b2977af9a5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T16:40:35.247616Z",
     "start_time": "2025-12-30T16:40:33.359054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!python -m pip install -U pip\n",
    "!python -m pip install \"torch>=2.2\" \"transformers>=4.41\" \"datasets>=2.19\" accelerate evaluate scikit-learn tqdm peft"
   ],
   "id": "942090d4e5a4bc21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (25.3)\r\n",
      "Requirement already satisfied: torch>=2.2 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (2.9.1)\r\n",
      "Requirement already satisfied: transformers>=4.41 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (4.57.3)\r\n",
      "Requirement already satisfied: datasets>=2.19 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (4.4.2)\r\n",
      "Requirement already satisfied: accelerate in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (1.12.0)\r\n",
      "Requirement already satisfied: evaluate in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (0.4.6)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (1.8.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (4.67.1)\r\n",
      "Collecting peft\r\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from torch>=2.2) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from torch>=2.2) (4.15.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from torch>=2.2) (1.14.0)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from torch>=2.2) (3.6.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from torch>=2.2) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from torch>=2.2) (2025.10.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from transformers>=4.41) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from transformers>=4.41) (2.4.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from transformers>=4.41) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from transformers>=4.41) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from transformers>=4.41) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from transformers>=4.41) (2.32.5)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from transformers>=4.41) (0.22.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from transformers>=4.41) (0.7.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.41) (1.2.0)\r\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from datasets>=2.19) (22.0.0)\r\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from datasets>=2.19) (0.4.0)\r\n",
      "Requirement already satisfied: pandas in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from datasets>=2.19) (2.3.3)\r\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from datasets>=2.19) (0.28.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from datasets>=2.19) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from datasets>=2.19) (0.70.18)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (3.13.2)\r\n",
      "Requirement already satisfied: anyio in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from httpx<1.0.0->datasets>=2.19) (4.12.0)\r\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from httpx<1.0.0->datasets>=2.19) (2025.11.12)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from httpx<1.0.0->datasets>=2.19) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from httpx<1.0.0->datasets>=2.19) (3.11)\r\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.19) (0.16.0)\r\n",
      "Requirement already satisfied: psutil in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from accelerate) (7.2.1)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\r\n",
      "Requirement already satisfied: joblib>=1.3.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from scikit-learn) (1.5.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.19) (1.22.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from requests->transformers>=4.41) (3.4.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from requests->transformers>=4.41) (2.6.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.2) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages (from jinja2->torch>=2.2) (3.0.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from pandas->datasets>=2.19) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from pandas->datasets>=2.19) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from pandas->datasets>=2.19) (2025.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/sinchang-geun/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19) (1.17.0)\r\n",
      "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m556.4/556.4 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m  \u001B[33m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: peft\r\n",
      "Successfully installed peft-0.18.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. MPS 확인(Apple Silicon GPU)",
   "id": "2f13552d00164b30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T01:46:36.883682Z",
     "start_time": "2025-12-31T01:46:35.505177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"mps available:\", torch.backends.mps.is_available())"
   ],
   "id": "359d32380d6a2854",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "mps available: True\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ],
   "id": "d05bd728245d5dce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. 데이터 파싱",
   "id": "74d0ec5f2144ba54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T01:46:40.516518Z",
     "start_time": "2025-12-31T01:46:40.291107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "RAW_PATH = Path(\"./naver_shopping.txt\")\n",
    "\n",
    "def load_reviews(min_len=5, max_n=None, seed=42):\n",
    "    random.seed(seed)\n",
    "    rows = []\n",
    "    with RAW_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split(\"\\t\", 1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            rating_s, text = parts\n",
    "            try:\n",
    "                rating = int(rating_s)\n",
    "            except:\n",
    "                continue\n",
    "            text = text.strip()\n",
    "            if len(text) < min_len:\n",
    "                continue\n",
    "            rows.append((rating, text))\n",
    "    random.shuffle(rows)\n",
    "    if max_n:\n",
    "        rows = rows[:max_n]\n",
    "    return rows\n",
    "\n",
    "rows = load_reviews(max_n=30000)  # 8GB면 처음엔 3만 이하 추천\n",
    "print(\"loaded:\", len(rows))\n",
    "print(rows[0])"
   ],
   "id": "dd4f60c06066e59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: 30000\n",
      "(2, '냄새랑 맛이 생각보다 너무 역해요')\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. 불만 유형(키워드) 분류",
   "id": "be7f27b09dd7efc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T01:46:48.614211Z",
     "start_time": "2025-12-31T01:46:48.599916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "COMPLAINT_RULES = {\n",
    "    \"배송\": [\"배송\", \"늦\", \"지연\", \"도착\", \"택배\"],\n",
    "    \"품질/불량\": [\"불량\", \"하자\", \"고장\", \"깨\", \"찢\", \"누수\", \"작동\", \"불안정\"],\n",
    "    \"포장\": [\"포장\", \"박스\", \"파손\", \"훼손\", \"완충\"],\n",
    "    \"가격/가성비\": [\"비싸\", \"가격\", \"가성비\", \"싸\", \"할인\"],\n",
    "    \"응대/서비스\": [\"응대\", \"문의\", \"연락\", \"고객센터\", \"불친절\"],\n",
    "}\n",
    "\n",
    "def detect_topics(text: str):\n",
    "    topics = []\n",
    "    for topic, kws in COMPLAINT_RULES.items():\n",
    "        if any(kw in text for kw in kws):\n",
    "            topics.append(topic)\n",
    "    return topics[:2]  # 너무 많으면 1~2개만"
   ],
   "id": "dbc5da775caaccc2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. 템플릿 기반 판매자 답변 생성",
   "id": "b711a984fd0708ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T01:46:52.765458Z",
     "start_time": "2025-12-31T01:46:52.736514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_seller_reply(rating: int, review: str) -> str:\n",
    "    topics = detect_topics(review)\n",
    "    topic_phrase = \" / \".join(topics) if topics else None\n",
    "\n",
    "    # 보상 제안(너무 구체적 금액은 피하고 옵션만 제시)\n",
    "    compensation = random.choice([\n",
    "        \"교환 또는 환불을 도와드리겠습니다.\",\n",
    "        \"확인 후 쿠폰/부분환불 등 가능한 보상안을 안내드리겠습니다.\",\n",
    "        \"불편을 줄이기 위해 교환/환불 절차를 빠르게 진행해드리겠습니다.\"\n",
    "    ])\n",
    "\n",
    "    # 긍정(4~5)\n",
    "    if rating >= 4:\n",
    "        extra = \"앞으로도 더 좋은 상품과 서비스로 보답하겠습니다.\"\n",
    "        upsell = random.choice([\n",
    "            \"재구매해주시면 감사하겠습니다.\",\n",
    "            \"다음에도 만족스러운 경험을 드리겠습니다.\",\n",
    "            \"소중한 후기 감사합니다.\"\n",
    "        ])\n",
    "        if topic_phrase:\n",
    "            return f\"안녕하세요, 고객님. {topic_phrase} 관련하여 만족하셨다니 정말 기쁩니다. {extra} {upsell}\"\n",
    "        return f\"안녕하세요, 고객님. 소중한 후기 감사합니다. {extra} {upsell}\"\n",
    "\n",
    "    # 부정(1~2)\n",
    "    if rating <= 2:\n",
    "        apology = \"불편을 드려 진심으로 죄송합니다.\"\n",
    "        ask = \"주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다.\"\n",
    "        if topic_phrase:\n",
    "            return f\"안녕하세요, 고객님. {topic_phrase} 관련하여 {apology} {ask} {compensation}\"\n",
    "        return f\"안녕하세요, 고객님. {apology} {ask} {compensation}\"\n",
    "\n",
    "    # 중립(3) — 과제에서는 제외해도 되고, 남겨도 됨\n",
    "    neutral = \"의견 남겨주셔서 감사합니다.\"\n",
    "    improve = \"말씀해주신 부분은 개선하여 더 나은 서비스로 보답하겠습니다.\"\n",
    "    if topic_phrase:\n",
    "        return f\"안녕하세요, 고객님. {topic_phrase} 관련하여 {neutral} {improve}\"\n",
    "    return f\"안녕하세요, 고객님. {neutral} {improve}\"\n",
    "\n",
    "# 샘플 확인\n",
    "for r, t in rows[:5]:\n",
    "    print(\"RATING:\", r)\n",
    "    print(\"REVIEW:\", t)\n",
    "    print(\"REPLY:\", make_seller_reply(r, t))\n",
    "    print(\"-\"*80)"
   ],
   "id": "801fe53949cf5aa7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATING: 2\n",
      "REVIEW: 냄새랑 맛이 생각보다 너무 역해요\n",
      "REPLY: 안녕하세요, 고객님. 불편을 드려 진심으로 죄송합니다. 주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다. 확인 후 쿠폰/부분환불 등 가능한 보상안을 안내드리겠습니다.\n",
      "--------------------------------------------------------------------------------\n",
      "RATING: 5\n",
      "REVIEW: 진짜대박좋아요만족^^\n",
      "REPLY: 안녕하세요, 고객님. 소중한 후기 감사합니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 다음에도 만족스러운 경험을 드리겠습니다.\n",
      "--------------------------------------------------------------------------------\n",
      "RATING: 5\n",
      "REVIEW: 좋아요 배송도 빠르고 가겨도 마니 저렴하고~~^^\n",
      "REPLY: 안녕하세요, 고객님. 배송 관련하여 만족하셨다니 정말 기쁩니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 다음에도 만족스러운 경험을 드리겠습니다.\n",
      "--------------------------------------------------------------------------------\n",
      "RATING: 1\n",
      "REVIEW: 1년 넘게 쓴 와이퍼보다 능력이 떨어지내요. 워셔액도 못 닦아내네요. 이런거 팔지 않으셨으면 좋겠네요\n",
      "REPLY: 안녕하세요, 고객님. 불편을 드려 진심으로 죄송합니다. 주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다. 확인 후 쿠폰/부분환불 등 가능한 보상안을 안내드리겠습니다.\n",
      "--------------------------------------------------------------------------------\n",
      "RATING: 2\n",
      "REVIEW: 진짜뚱뚱하신분만사셔야될듯\n",
      "REPLY: 안녕하세요, 고객님. 불편을 드려 진심으로 죄송합니다. 주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다. 교환 또는 환불을 도와드리겠습니다.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6. 학습 데이터 구성 + split",
   "id": "519a046a30f10c57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T01:47:52.006929Z",
     "start_time": "2025-12-31T01:47:44.961211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_example(rating, review):\n",
    "    # 프롬프트: 역할/규칙/입력\n",
    "    prompt = (\n",
    "        \"### 역할: 당신은 온라인 쇼핑몰 판매자입니다.\\n\"\n",
    "        \"### 규칙:\\n\"\n",
    "        \"- 한국어 존댓말로 정중하게 작성\\n\"\n",
    "        \"- 2~4문장으로 간결하게\\n\"\n",
    "        \"- 부정 리뷰(1~2점)에는 사과+해결책+보상(쿠폰/교환/환불 중 하나) 포함\\n\"\n",
    "        \"- 긍정 리뷰(4~5점)에는 감사+재구매/재방문 유도 포함\\n\"\n",
    "        \"### 고객 리뷰:\\n\"\n",
    "        f\"{review}\\n\"\n",
    "        \"### 판매자 답변:\\n\"\n",
    "    )\n",
    "    completion = make_seller_reply(rating, review)\n",
    "    return {\"prompt\": prompt, \"completion\": completion, \"rating\": rating, \"review\": review}\n",
    "\n",
    "# 3점은 빼서 “명확한” 긍/부정만 학습(추천)\n",
    "filtered = [(r, t) for (r, t) in rows if r in (1,2,4,5)]\n",
    "data = [build_example(r, t) for r, t in filtered[:20000]]  # 최대 2만개만\n",
    "\n",
    "train_data, valid_data = train_test_split(data, test_size=0.05, random_state=42)\n",
    "\n",
    "print(len(train_data), len(valid_data))\n",
    "print(train_data[0][\"prompt\"])\n",
    "print(\"->\", train_data[0][\"completion\"])"
   ],
   "id": "a5e5a366160b74a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000 1000\n",
      "### 역할: 당신은 온라인 쇼핑몰 판매자입니다.\n",
      "### 규칙:\n",
      "- 한국어 존댓말로 정중하게 작성\n",
      "- 2~4문장으로 간결하게\n",
      "- 부정 리뷰(1~2점)에는 사과+해결책+보상(쿠폰/교환/환불 중 하나) 포함\n",
      "- 긍정 리뷰(4~5점)에는 감사+재구매/재방문 유도 포함\n",
      "### 고객 리뷰:\n",
      "저렴하게 좋은 제품을 구매한거 같아 만족해요^^\n",
      "### 판매자 답변:\n",
      "\n",
      "-> 안녕하세요, 고객님. 소중한 후기 감사합니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 재구매해주시면 감사하겠습니다.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. 모델/토크나이저 로드 + LoRA 적용",
   "id": "63d01d32d340f820"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T02:03:53.230915Z",
     "start_time": "2025-12-31T02:03:48.276209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "MODEL_ID = \"skt/kogpt2-base-v2\"   # 안 되면 여기만 다른 KoGPT2 repo로 변경\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "\n",
    "# GPT2류는 pad_token이 없는 경우가 많아서 eos로 맞추는 게 안전\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
    "model.config.use_cache = False\n",
    "model.gradient_checkpointing_enable()  # 메모리 절약\n",
    "\n",
    "# LoRA 설정 (GPT-2 계열에서 흔히 쓰는 target)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],  # GPT-2 계열에 흔한 모듈명\n",
    "    fan_in_fan_out=True\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "model.to(device)"
   ],
   "id": "37a82ec5c10af318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n",
      "trainable params: 811,008 || all params: 125,975,040 || trainable%: 0.6438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(51200, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2304, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D(nf=3072, nx=768)\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=3072)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "8. Dataset 만들기 + 토크나이징",
   "id": "8556d011fc204819"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T02:05:50.199758Z",
     "start_time": "2025-12-31T02:05:45.110106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def pack_text(ex):\n",
    "    return ex[\"prompt\"] + ex[\"completion\"]\n",
    "\n",
    "train_ds = Dataset.from_dict({\"text\": [pack_text(x) for x in train_data]})\n",
    "valid_ds = Dataset.from_dict({\"text\": [pack_text(x) for x in valid_data]})\n",
    "\n",
    "MAX_LEN = 192  # 8GB 추천(256도 가능하지만 터질 수 있음)\n",
    "\n",
    "def tok(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "train_tok = train_ds.map(tok, batched=True, remove_columns=[\"text\"])\n",
    "valid_tok = valid_ds.map(tok, batched=True, remove_columns=[\"text\"])\n"
   ],
   "id": "7ef416af57b56da8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/19000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e247255f950c468ab10cfee249c3d3ca"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ae314e0f4894994bf79c23f244a5238"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "9. Trainer로 학습",
   "id": "40afa70a49585bb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T02:16:21.353273Z",
     "start_time": "2025-12-31T02:10:41.511636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"outputs/seller_reply_lora\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=32,   # 배치 늘린 효과\n",
    "    learning_rate=2e-4,              # LoRA는 보통 LR을 조금 높게\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=valid_tok,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"outputs/seller_reply_lora\")\n",
    "tokenizer.save_pretrained(\"outputs/seller_reply_lora\")\n"
   ],
   "id": "60bf0f086be1ca5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 43/594 05:25 < 1:12:52, 0.13 it/s, Epoch 0.07/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "80ebaa28e0d6bfcc60d787763afc7bba"
     }
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m      5\u001B[39m args = TrainingArguments(\n\u001B[32m      6\u001B[39m     output_dir=\u001B[33m\"\u001B[39m\u001B[33moutputs/seller_reply_lora\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      7\u001B[39m     per_device_train_batch_size=\u001B[32m1\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     17\u001B[39m     report_to=\u001B[33m\"\u001B[39m\u001B[33mnone\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     18\u001B[39m )\n\u001B[32m     20\u001B[39m trainer = Trainer(\n\u001B[32m     21\u001B[39m     model=model,\n\u001B[32m     22\u001B[39m     args=args,\n\u001B[32m   (...)\u001B[39m\u001B[32m     25\u001B[39m     data_collator=collator,\n\u001B[32m     26\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m trainer.save_model(\u001B[33m\"\u001B[39m\u001B[33moutputs/seller_reply_lora\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     30\u001B[39m tokenizer.save_pretrained(\u001B[33m\"\u001B[39m\u001B[33moutputs/seller_reply_lora\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages/transformers/trainer.py:2325\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2323\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2324\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2325\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2326\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2327\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2329\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2330\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/anaconda3/envs/final_exam/lib/python3.11/site-packages/transformers/trainer.py:2679\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2673\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m   2674\u001B[39m     tr_loss_step = \u001B[38;5;28mself\u001B[39m.training_step(model, inputs, num_items_in_batch)\n\u001B[32m   2676\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2677\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2678\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m-> \u001B[39m\u001B[32m2679\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43misinf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss_step\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m   2680\u001B[39m ):\n\u001B[32m   2681\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2682\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n\u001B[32m   2683\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "10. 생성 함수",
   "id": "d2d37e368bf3342d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "FT_DIR = \"outputs/seller_reply_lora\"\n",
    "\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(FT_DIR, use_fast=True)\n",
    "if ft_tokenizer.pad_token is None:\n",
    "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
    "\n",
    "ft_model = AutoModelForCausalLM.from_pretrained(FT_DIR).to(device)\n",
    "ft_model.config.use_cache = False\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_reply(prompt, max_new_tokens=80, temperature=0.7):\n",
    "    inputs = ft_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    out = ft_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        eos_token_id=ft_tokenizer.eos_token_id,\n",
    "        pad_token_id=ft_tokenizer.pad_token_id,\n",
    "    )\n",
    "    text = ft_tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    # prompt 이후만 출력\n",
    "    if prompt in text:\n",
    "        return text.split(prompt, 1)[1].strip()\n",
    "    return text.strip()\n"
   ],
   "id": "7ff2c89fbd72024e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "11. 프롬프트 3종 비교(단순/조건/강한 제약)",
   "id": "73f5a67bde84e9d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_review_neg = \"배송이 너무 늦고 포장도 찢어져서 왔어요. 정말 실망입니다.\"\n",
    "sample_review_pos = \"배송도 빠르고 제품 품질이 좋아요. 재구매 의사 있습니다!\"\n",
    "\n",
    "def prompt_basic(review):\n",
    "    return f\"리뷰: {review}\\n판매자 답변:\"\n",
    "\n",
    "def prompt_with_rules(review, neg=True):\n",
    "    rules = (\n",
    "        \"규칙: 한국어 존댓말, 2~4문장.\\n\"\n",
    "        + (\"사과+해결책+보상(쿠폰/교환/환불 중 하나)을 반드시 포함.\\n\" if neg else \"감사+재구매 유도 포함.\\n\")\n",
    "    )\n",
    "    return f\"{rules}리뷰: {review}\\n판매자 답변:\"\n",
    "\n",
    "def prompt_project_style(review):\n",
    "    # 학습 때 쓰던 포맷(일관성 최고)\n",
    "    return (\n",
    "        \"### 역할: 당신은 온라인 쇼핑몰 판매자입니다.\\n\"\n",
    "        \"### 규칙:\\n\"\n",
    "        \"- 한국어 존댓말로 정중하게 작성\\n\"\n",
    "        \"- 2~4문장으로 간결하게\\n\"\n",
    "        \"- 부정 리뷰에는 사과+해결책+보상 제안 포함\\n\"\n",
    "        \"- 긍정 리뷰에는 감사+재구매 유도 포함\\n\"\n",
    "        \"### 고객 리뷰:\\n\"\n",
    "        f\"{review}\\n\"\n",
    "        \"### 판매자 답변:\\n\"\n",
    "    )\n",
    "\n",
    "for p in [prompt_basic(sample_review_neg),\n",
    "          prompt_with_rules(sample_review_neg, neg=True),\n",
    "          prompt_project_style(sample_review_neg)]:\n",
    "    print(\"PROMPT:\\n\", p)\n",
    "    print(\"OUTPUT:\\n\", generate_reply(p))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "for p in [prompt_basic(sample_review_pos),\n",
    "          prompt_with_rules(sample_review_pos, neg=False),\n",
    "          prompt_project_style(sample_review_pos)]:\n",
    "    print(\"PROMPT:\\n\", p)\n",
    "    print(\"OUTPUT:\\n\", generate_reply(p))\n",
    "    print(\"=\"*80)\n"
   ],
   "id": "b80027d34b35cc89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "12. 규칙 준수 점수(간단 룰 기반)",
   "id": "21de0f2b77feaf54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "\n",
    "def score_reply(review_rating, reply):\n",
    "    score = 0\n",
    "    # 문장 수(대충 .?! 기준)\n",
    "    sentences = [s for s in re.split(r\"[.?!]\\s*\", reply) if s.strip()]\n",
    "    if 2 <= len(sentences) <= 4:\n",
    "        score += 1\n",
    "\n",
    "    if review_rating <= 2:\n",
    "        if any(k in reply for k in [\"죄송\", \"사과\"]):\n",
    "            score += 1\n",
    "        if any(k in reply for k in [\"교환\", \"환불\", \"쿠폰\", \"보상\"]):\n",
    "            score += 1\n",
    "    if review_rating >= 4:\n",
    "        if any(k in reply for k in [\"감사\", \"고맙\"]):\n",
    "            score += 1\n",
    "        if any(k in reply for k in [\"재구매\", \"다음에도\", \"또 이용\"]):\n",
    "            score += 1\n",
    "    return score\n",
    "\n",
    "# 샘플 50개로 점수 보기\n",
    "samples = random.sample(filtered, 50)\n",
    "total = 0\n",
    "for r, review in samples:\n",
    "    p = prompt_project_style(review)\n",
    "    out = generate_reply(p)\n",
    "    total += score_reply(r, out)\n",
    "\n",
    "print(\"avg rule score:\", total/50)\n"
   ],
   "id": "796300a9b1260e83"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_exam",
   "language": "python",
   "name": "final_exam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
