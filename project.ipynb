{
  "cells": [
    {
      "metadata": {
        "id": "ccd6c8e71c0953a7"
      },
      "cell_type": "markdown",
      "source": [
        "### 파이썬 버전 확인"
      ],
      "id": "ccd6c8e71c0953a7"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq011bQGe8ZH",
        "outputId": "6857e137-f75a-4004-c58c-bef81a87d72c"
      },
      "id": "zq011bQGe8ZH",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"
          ]
        }
      ],
      "execution_count": 51
    },
    {
      "metadata": {
        "id": "fa64466eca1790b6"
      },
      "cell_type": "markdown",
      "source": [
        "## 네이버 쇼핑 리뷰를 보고 판매자 답변 자동 생성하기(정중/사과/보상 제안)"
      ],
      "id": "fa64466eca1790b6"
    },
    {
      "metadata": {
        "id": "623f33a35a750969"
      },
      "cell_type": "markdown",
      "source": [
        "#### 데이터 출처 : https://github.com/bab2min/corpus"
      ],
      "id": "623f33a35a750969"
    },
    {
      "metadata": {
        "id": "b86bc02f482a4bb6"
      },
      "cell_type": "markdown",
      "source": [
        "##### 유의사항 : 로컬에서 너무 느리면 Colab에서 실행해주세요. (Colab 사용 시 python 3.11, GPU 사용 필요)"
      ],
      "id": "b86bc02f482a4bb6"
    },
    {
      "metadata": {
        "id": "49d892c43b5ef03f"
      },
      "cell_type": "markdown",
      "source": [
        "1. 라이브러리 설치 (Colab GPU / Python 3.11)"
      ],
      "id": "49d892c43b5ef03f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-31T05:48:56.603556Z",
          "start_time": "2025-12-31T05:48:53.821756Z"
        },
        "id": "8cddb851f8b3d441"
      },
      "cell_type": "code",
      "source": [
        "# Colab은 보통 torch 2.6.0+cu124가 이미 설치되어 있습니다.\n",
        "# 설치가 안 되어 있거나 버전을 맞추고 싶다면 주석 해제하여 실행하세요.\n",
        "# --- 맥북(Apple Silicon, CPU/MPS) ---\n",
        "#!pip install -q -U pip\n",
        "#!pip install -q \"torch>=2.2\" \"torchvision>=0.17\" \"torchaudio>=2.2\" \\\n",
        "#   \"transformers>=4.41\" \"datasets>=2.19\" accelerate evaluate \\\n",
        "#    \"scikit-learn>=1.2,<1.7\" tqdm peft\n",
        "\n",
        "# --- Colab GPU(T4 등, CUDA 12.4) ---\n",
        "# Colab에 기본 설치된 torch 2.6.0+cu124가 있으면 이 블록은 생략해도 됩니다.\n",
        "# 없거나 버전을 맞추고 싶을 때만 주석 해제해서 실행하세요.\n",
        "# !pip install -q --index-url https://download.pytorch.org/whl/cu124 \\\n",
        "#     torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124\n",
        "# 공통 패키지 설치\n",
        "!pip install -q -U \"transformers>=4.41\" \"datasets>=2.19\" accelerate evaluate \\\n",
        "    \"scikit-learn>=1.2,<1.7\" tqdm peft"
      ],
      "id": "8cddb851f8b3d441",
      "outputs": [],
      "execution_count": 52
    },
    {
      "metadata": {
        "id": "74d0ec5f2144ba54"
      },
      "cell_type": "markdown",
      "source": [
        "2. 데이터 파싱"
      ],
      "id": "74d0ec5f2144ba54"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd4f60c06066e59",
        "outputId": "6c8d5bad-d9ea-4f5a-975d-4d18724c8e8c",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:49:03.970774Z",
          "start_time": "2025-12-31T05:49:03.752921Z"
        }
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "RAW_PATH = Path(\"./naver_shopping.txt\")\n",
        "\n",
        "def load_reviews(min_len=5, max_n=None, seed=42):\n",
        "    random.seed(seed)\n",
        "    rows = []\n",
        "    with RAW_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split(\"\\t\", 1)\n",
        "            if len(parts) != 2:\n",
        "                continue\n",
        "            rating_s, text = parts\n",
        "            try:\n",
        "                rating = int(rating_s)\n",
        "            except:\n",
        "                continue\n",
        "            text = text.strip()\n",
        "            if len(text) < min_len:\n",
        "                continue\n",
        "            rows.append((rating, text))\n",
        "    random.shuffle(rows)\n",
        "    if max_n:\n",
        "        rows = rows[:max_n]\n",
        "    return rows\n",
        "\n",
        "rows = load_reviews(max_n=30000)  # 8GB면 처음엔 3만 이하 추천\n",
        "print(\"loaded:\", len(rows))\n",
        "print(rows[0])"
      ],
      "id": "dd4f60c06066e59",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded: 30000\n",
            "(2, '냄새랑 맛이 생각보다 너무 역해요')\n"
          ]
        }
      ],
      "execution_count": 53
    },
    {
      "metadata": {
        "id": "be7f27b09dd7efc"
      },
      "cell_type": "markdown",
      "source": [
        "3. 불만 유형(키워드) 분류"
      ],
      "id": "be7f27b09dd7efc"
    },
    {
      "metadata": {
        "id": "dbc5da775caaccc2",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:49:09.777103Z",
          "start_time": "2025-12-31T05:49:09.766866Z"
        }
      },
      "cell_type": "code",
      "source": [
        "COMPLAINT_RULES = {\n",
        "    \"배송\": [\"배송\", \"늦\", \"지연\", \"도착\", \"택배\"],\n",
        "    \"품질/불량\": [\"불량\", \"하자\", \"고장\", \"깨\", \"찢\", \"누수\", \"작동\", \"불안정\"],\n",
        "    \"포장\": [\"포장\", \"박스\", \"파손\", \"훼손\", \"완충\"],\n",
        "    \"가격/가성비\": [\"비싸\", \"가격\", \"가성비\", \"싸\", \"할인\"],\n",
        "    \"응대/서비스\": [\"응대\", \"문의\", \"연락\", \"고객센터\", \"불친절\"],\n",
        "}\n",
        "\n",
        "def detect_topics(text: str):\n",
        "    topics = []\n",
        "    for topic, kws in COMPLAINT_RULES.items():\n",
        "        if any(kw in text for kw in kws):\n",
        "            topics.append(topic)\n",
        "    return topics[:2]"
      ],
      "id": "dbc5da775caaccc2",
      "outputs": [],
      "execution_count": 54
    },
    {
      "metadata": {
        "id": "b711a984fd0708ca"
      },
      "cell_type": "markdown",
      "source": [
        "4. 템플릿 기반 판매자 답변 생성"
      ],
      "id": "b711a984fd0708ca"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "801fe53949cf5aa7",
        "outputId": "fb7d903c-7861-4c22-bfb0-0365e91a1854",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:49:12.904240Z",
          "start_time": "2025-12-31T05:49:12.868637Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def make_seller_reply(rating: int, review: str) -> str:\n",
        "    topics = detect_topics(review)\n",
        "    topic_phrase = \" / \".join(topics) if topics else None\n",
        "\n",
        "    # 보상 제안(너무 구체적 금액은 피하고 옵션만 제시)\n",
        "    compensation = random.choice([\n",
        "        \"교환 또는 환불을 도와드리겠습니다.\",\n",
        "        \"확인 후 쿠폰/부분환불 등 가능한 보상안을 안내드리겠습니다.\",\n",
        "        \"불편을 줄이기 위해 교환/환불 절차를 빠르게 진행해드리겠습니다.\"\n",
        "    ])\n",
        "\n",
        "    # 긍정(4~5)\n",
        "    if rating >= 4:\n",
        "        extra = \"앞으로도 더 좋은 상품과 서비스로 보답하겠습니다.\"\n",
        "        upsell = random.choice([\n",
        "            \"재구매해주시면 감사하겠습니다.\",\n",
        "            \"다음에도 만족스러운 경험을 드리겠습니다.\",\n",
        "            \"소중한 후기 감사합니다.\"\n",
        "        ])\n",
        "        if topic_phrase:\n",
        "            return f\"안녕하세요, 고객님. {topic_phrase} 관련하여 만족하셨다니 정말 기쁩니다. {extra} {upsell}\"\n",
        "        return f\"안녕하세요, 고객님. 소중한 후기 감사합니다. {extra} {upsell}\"\n",
        "\n",
        "    # 부정(1~2)\n",
        "    if rating <= 2:\n",
        "        apology = \"불편을 드려 진심으로 죄송합니다.\"\n",
        "        ask = \"주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다.\"\n",
        "        if topic_phrase:\n",
        "            return f\"안녕하세요, 고객님. {topic_phrase} 관련하여 {apology} {ask} {compensation}\"\n",
        "        return f\"안녕하세요, 고객님. {apology} {ask} {compensation}\"\n",
        "\n",
        "    # 중립(3)\n",
        "    neutral = \"의견 남겨주셔서 감사합니다.\"\n",
        "    improve = \"말씀해주신 부분은 개선하여 더 나은 서비스로 보답하겠습니다.\"\n",
        "    if topic_phrase:\n",
        "        return f\"안녕하세요, 고객님. {topic_phrase} 관련하여 {neutral} {improve}\"\n",
        "    return f\"안녕하세요, 고객님. {neutral} {improve}\"\n",
        "\n",
        "# 샘플 확인\n",
        "for r, t in rows[:5]:\n",
        "    print(\"RATING:\", r)\n",
        "    print(\"REVIEW:\", t)\n",
        "    print(\"REPLY:\", make_seller_reply(r, t))\n",
        "    print(\"-\"*80)"
      ],
      "id": "801fe53949cf5aa7",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RATING: 2\n",
            "REVIEW: 냄새랑 맛이 생각보다 너무 역해요\n",
            "REPLY: 안녕하세요, 고객님. 불편을 드려 진심으로 죄송합니다. 주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다. 확인 후 쿠폰/부분환불 등 가능한 보상안을 안내드리겠습니다.\n",
            "--------------------------------------------------------------------------------\n",
            "RATING: 5\n",
            "REVIEW: 진짜대박좋아요만족^^\n",
            "REPLY: 안녕하세요, 고객님. 소중한 후기 감사합니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 다음에도 만족스러운 경험을 드리겠습니다.\n",
            "--------------------------------------------------------------------------------\n",
            "RATING: 5\n",
            "REVIEW: 좋아요 배송도 빠르고 가겨도 마니 저렴하고~~^^\n",
            "REPLY: 안녕하세요, 고객님. 배송 관련하여 만족하셨다니 정말 기쁩니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 다음에도 만족스러운 경험을 드리겠습니다.\n",
            "--------------------------------------------------------------------------------\n",
            "RATING: 1\n",
            "REVIEW: 1년 넘게 쓴 와이퍼보다 능력이 떨어지내요. 워셔액도 못 닦아내네요. 이런거 팔지 않으셨으면 좋겠네요\n",
            "REPLY: 안녕하세요, 고객님. 불편을 드려 진심으로 죄송합니다. 주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다. 확인 후 쿠폰/부분환불 등 가능한 보상안을 안내드리겠습니다.\n",
            "--------------------------------------------------------------------------------\n",
            "RATING: 2\n",
            "REVIEW: 진짜뚱뚱하신분만사셔야될듯\n",
            "REPLY: 안녕하세요, 고객님. 불편을 드려 진심으로 죄송합니다. 주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다. 교환 또는 환불을 도와드리겠습니다.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": 55
    },
    {
      "metadata": {
        "id": "519a046a30f10c57"
      },
      "cell_type": "markdown",
      "source": [
        "5. 학습 데이터 구성 + split"
      ],
      "id": "519a046a30f10c57"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5e5a366160b74a4",
        "outputId": "21e9a1c8-a327-4685-9c62-98ba88318035",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:49:17.584362Z",
          "start_time": "2025-12-31T05:49:17.406684Z"
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def build_example(rating, review):\n",
        "    # 프롬프트: 역할/규칙/입력\n",
        "    prompt = (\n",
        "        \"### 역할: 당신은 온라인 쇼핑몰 판매자입니다.\\n\"\n",
        "        \"### 규칙:\\n\"\n",
        "        \"- 한국어 존댓말로 정중하게 작성\\n\"\n",
        "        \"- 2~4문장으로 간결하게\\n\"\n",
        "        \"- 부정 리뷰(1~2점)에는 사과+해결책+보상(쿠폰/교환/환불 중 하나) 포함\\n\"\n",
        "        \"- 긍정 리뷰(4~5점)에는 감사+재구매/재방문 유도 포함\\n\"\n",
        "        \"### 고객 리뷰:\\n\"\n",
        "        f\"{review}\\n\"\n",
        "        \"### 판매자 답변:\\n\"\n",
        "    )\n",
        "    completion = make_seller_reply(rating, review)\n",
        "    return {\"prompt\": prompt, \"completion\": completion, \"rating\": rating, \"review\": review}\n",
        "\n",
        "# 3점은 빼서 “명확한” 긍/부정만 학습\n",
        "filtered = [(r, t) for (r, t) in rows if r in (1,2,4,5)]\n",
        "data = [build_example(r, t) for r, t in filtered[:20000]]  # 최대 2만개만\n",
        "\n",
        "train_data, valid_data = train_test_split(data, test_size=0.05, random_state=42)\n",
        "\n",
        "print(len(train_data), len(valid_data))\n",
        "print(train_data[0][\"prompt\"])\n",
        "print(\"->\", train_data[0][\"completion\"])"
      ],
      "id": "a5e5a366160b74a4",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19000 1000\n",
            "### 역할: 당신은 온라인 쇼핑몰 판매자입니다.\n",
            "### 규칙:\n",
            "- 한국어 존댓말로 정중하게 작성\n",
            "- 2~4문장으로 간결하게\n",
            "- 부정 리뷰(1~2점)에는 사과+해결책+보상(쿠폰/교환/환불 중 하나) 포함\n",
            "- 긍정 리뷰(4~5점)에는 감사+재구매/재방문 유도 포함\n",
            "### 고객 리뷰:\n",
            "저렴하게 좋은 제품을 구매한거 같아 만족해요^^\n",
            "### 판매자 답변:\n",
            "\n",
            "-> 안녕하세요, 고객님. 소중한 후기 감사합니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 재구매해주시면 감사하겠습니다.\n"
          ]
        }
      ],
      "execution_count": 56
    },
    {
      "metadata": {
        "id": "63d01d32d340f820"
      },
      "cell_type": "markdown",
      "source": [
        "6. 모델/토크나이저 로드 + LoRA 적용, fine-tuning"
      ],
      "id": "63d01d32d340f820"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37a82ec5c10af318",
        "outputId": "7a3d6ad3-9b90-4ba6-85e4-9d97fba16d56",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:49:38.804849Z",
          "start_time": "2025-12-31T05:49:30.366766Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import torch, platform\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "MODEL_ID = \"skt/kogpt2-base-v2\"\n",
        "def pick_device():\n",
        "    # Colab GPU (CUDA)\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    # Apple Silicon (MPS)\n",
        "    if platform.system() == \"Darwin\" and torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    # fallback CPU\n",
        "    return \"cpu\"\n",
        "device = pick_device()\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"mps available:\", torch.backends.mps.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"gpu name:\", torch.cuda.get_device_name(0))\n",
        "print(\"device:\", device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "\n",
        "# eos로 맞추는 게 안전\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
        "model.config.use_cache = False\n",
        "model.gradient_checkpointing_enable()  # 메모리 절약\n",
        "\n",
        "# LoRA 설정\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],  # GPT-2 계열에 흔한 모듈명\n",
        "    fan_in_fan_out=True\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "model.to(device)"
      ],
      "id": "37a82ec5c10af318",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.6.0+cu124\n",
            "cuda available: True\n",
            "mps available: False\n",
            "gpu name: Tesla T4\n",
            "device: cuda\n",
            "trainable params: 811,008 || all params: 125,975,040 || trainable%: 0.6438\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): GPT2LMHeadModel(\n",
              "      (transformer): GPT2Model(\n",
              "        (wte): Embedding(51200, 768)\n",
              "        (wpe): Embedding(1024, 768)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (h): ModuleList(\n",
              "          (0-11): 12 x GPT2Block(\n",
              "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): GPT2Attention(\n",
              "              (c_attn): lora.Linear(\n",
              "                (base_layer): Conv1D(nf=2304, nx=768)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (c_proj): lora.Linear(\n",
              "                (base_layer): Conv1D(nf=768, nx=768)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): GPT2MLP(\n",
              "              (c_fc): Conv1D(nf=3072, nx=768)\n",
              "              (c_proj): lora.Linear(\n",
              "                (base_layer): Conv1D(nf=768, nx=3072)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "execution_count": 57
    },
    {
      "metadata": {
        "id": "8556d011fc204819"
      },
      "cell_type": "markdown",
      "source": [
        "7. Dataset 만들기 + 토크나이징"
      ],
      "id": "8556d011fc204819"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "00a8b8a2264c4e95a3a471fbce39c342",
            "4383e05429fb4761bc32c999f43cfcbc",
            "a6e85e24d92e4854a4d216b0883b1a67",
            "43404553c17642ac8e4ecb021e5b036c",
            "6e2d646905274e4f8058af2ef6ae3a4d",
            "7695998435804ea5922e157bb4ed2339",
            "161e7732a7be4a968cc8522ce51420b0",
            "4f46f2930a464c2dbb7b0d243713f880",
            "838b233270af40f6b3153c8f4a7cb256",
            "7369d46ebdff4efb91d3a8f053babf00",
            "f5a646804d7e444d9dc931651375e22e",
            "0da72e48fc9045abb1dea76c4135c8ce",
            "7d91100e7f8a49ffb1089958dd3dbecc",
            "e4cdd7a39ef14facac769658323a6121",
            "5ec0211749b141ec881aa6c5095d65ef",
            "f1c18db8d79a48feb830c944a93517db",
            "6df4483f0f7f4e369b2264eb6d78e22a",
            "a49e868014d74b04b60ee1369ea1ac32",
            "de4f7e6b576d4ea89285a5ffd9ae33b6",
            "fa88d917669040fa9076483bec21f9f5",
            "53e21caac0e14abaa156363da896b21a",
            "b4bb8b5ff6354ad796fd1a53196ef700"
          ]
        },
        "id": "7ef416af57b56da8",
        "outputId": "1f14c7ae-c8e8-41b0-a940-26218a30b48b",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:49:43.899773Z",
          "start_time": "2025-12-31T05:49:41.763077Z"
        }
      },
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def pack_text(ex):\n",
        "    return ex[\"prompt\"] + ex[\"completion\"]\n",
        "\n",
        "train_ds = Dataset.from_dict({\"text\": [pack_text(x) for x in train_data]})\n",
        "valid_ds = Dataset.from_dict({\"text\": [pack_text(x) for x in valid_data]})\n",
        "\n",
        "MAX_LEN = 192\n",
        "\n",
        "def tok(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "train_tok = train_ds.map(tok, batched=True, remove_columns=[\"text\"])\n",
        "valid_tok = valid_ds.map(tok, batched=True, remove_columns=[\"text\"])\n"
      ],
      "id": "7ef416af57b56da8",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00a8b8a2264c4e95a3a471fbce39c342"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0da72e48fc9045abb1dea76c4135c8ce"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 58
    },
    {
      "metadata": {
        "id": "40afa70a49585bb9"
      },
      "cell_type": "markdown",
      "source": [
        "8. Trainer로 학습"
      ],
      "id": "40afa70a49585bb9"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "60bf0f086be1ca5a",
        "outputId": "9161288e-0b79-46ab-93a0-115733aa076e",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:50:21.622761Z",
          "start_time": "2025-12-31T05:49:48.545779Z"
        }
      },
      "cell_type": "code",
      "source": [
        "import os, random, inspect, platform\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        ")\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# 디바이스 선택 (CUDA 우선, 그다음 MPS, 아니면 CPU)\n",
        "def pick_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    if platform.system() == \"Darwin\" and torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    return \"cpu\"\n",
        "\n",
        "device = pick_device()\n",
        "print(\"torch =\", torch.__version__)\n",
        "print(\"cuda available =\", torch.cuda.is_available())\n",
        "print(\"mps available =\", torch.backends.mps.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"gpu name =\", torch.cuda.get_device_name(0))\n",
        "print(\"device =\", device)\n",
        "\n",
        "# 전제 체크\n",
        "assert \"tokenizer\" in globals(), \"tokenizer가 먼저 정의돼야 합니다.\"\n",
        "assert \"train_tok\" in globals(), \"train_tok(토큰화된 학습 데이터셋)이 먼저 정의돼야 합니다.\"\n",
        "valid_tok = globals().get(\"valid_tok\", None)\n",
        "MODEL_ID = globals().get(\"MODEL_ID\", \"skt/kogpt2-base-v2\")\n",
        "\n",
        "# tokenizer / special token 안전 확인\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"len(tokenizer) =\", len(tokenizer))\n",
        "print(\"pad_token_id =\", tokenizer.pad_token_id, \"eos_token_id =\", tokenizer.eos_token_id)\n",
        "\n",
        "# 베이스 모델 로드 + 임베딩 리사이즈\n",
        "base_model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "if tokenizer.eos_token_id is not None:\n",
        "    base_model.config.eos_token_id = tokenizer.eos_token_id\n",
        "base_model.config.use_cache = False\n",
        "base_model.gradient_checkpointing_enable()\n",
        "\n",
        "# LoRA 설정\n",
        "lora_config = globals().get(\"lora_config\", None)\n",
        "if lora_config is None:\n",
        "    lora_config = LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        target_modules=[\"c_attn\"],\n",
        "    )\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "\n",
        "# 디바이스로 이동 (CUDA/MPS/CPU)\n",
        "model.to(device)\n",
        "try:\n",
        "    model.print_trainable_parameters()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 데이터 콜레이터\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# TrainingArguments\n",
        "OUTPUT_DIR = \"outputs/seller_reply_lora\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "common_kwargs = dict(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=16,\n",
        "    learning_rate=2e-4,\n",
        "    max_steps=200,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=25,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        "    fp16=(device == \"cuda\"),  # CUDA에서만 fp16, MPS/CPU는 float32\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "try:\n",
        "    args = TrainingArguments(\n",
        "        **common_kwargs,\n",
        "        eval_strategy=\"steps\" if valid_tok is not None else \"no\",\n",
        "        eval_steps=200 if valid_tok is not None else None,\n",
        "    )\n",
        "except TypeError:\n",
        "    args = TrainingArguments(\n",
        "        **common_kwargs,\n",
        "        evaluation_strategy=\"steps\" if valid_tok is not None else \"no\",\n",
        "        eval_steps=200 if valid_tok is not None else None,\n",
        "    )\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=valid_tok if valid_tok is not None else None,\n",
        "    data_collator=collator,\n",
        ")\n",
        "if hasattr(trainer, \"label_names\"):\n",
        "    trainer.label_names = [\"labels\"]\n",
        "\n",
        "# 범위 체크\n",
        "emb_size = model.get_input_embeddings().weight.shape[0]\n",
        "idxs = random.sample(range(len(train_tok)), k=min(200, len(train_tok)))\n",
        "mx = max(max(train_tok[i][\"input_ids\"]) for i in idxs)\n",
        "print(\"model emb size =\", emb_size, \"| sample input_id max =\", mx)\n",
        "assert mx < emb_size, f\"토큰 id({mx})가 임베딩 크기({emb_size}) 이상입니다. resize가 적용됐는지 확인하세요.\"\n",
        "\n",
        "# 학습\n",
        "train_result = trainer.train()\n",
        "\n",
        "# 저장\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "\n",
        "print(\"✅ Done. Saved to:\", OUTPUT_DIR)\n",
        "print(\"Train result:\", train_result)"
      ],
      "id": "60bf0f086be1ca5a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch = 2.6.0+cu124\n",
            "cuda available = True\n",
            "mps available = False\n",
            "gpu name = Tesla T4\n",
            "device = cuda\n",
            "len(tokenizer) = 51201\n",
            "pad_token_id = 51200 eos_token_id = 51200\n",
            "trainable params: 811,008 || all params: 125,975,808 || trainable%: 0.6438\n",
            "model emb size = 51201 | sample input_id max = 51200\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 05:47, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.691400</td>\n",
              "      <td>0.653073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:309: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:309: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Done. Saved to: outputs/seller_reply_lora\n",
            "Train result: TrainOutput(global_step=200, training_loss=1.2348973846435547, metrics={'train_runtime': 348.5839, 'train_samples_per_second': 9.18, 'train_steps_per_second': 0.574, 'total_flos': 316540138291200.0, 'train_loss': 1.2348973846435547, 'epoch': 0.16842105263157894})\n"
          ]
        }
      ],
      "execution_count": 59
    },
    {
      "metadata": {
        "id": "d2d37e368bf3342d"
      },
      "cell_type": "markdown",
      "source": [
        "9. 생성 함수"
      ],
      "id": "d2d37e368bf3342d"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ff2c89fbd72024e",
        "outputId": "ac1c0789-9c2c-4846-d893-ed63f69dee00"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device = cuda\n",
            "tokenizer class = GPT2TokenizerFast\n",
            "len(tokenizer) = 51201\n",
            "bos: 51200 eos: 51200 pad: 3\n",
            "emb size       = 51201\n",
            "vocab==emb ?   = True\n",
            "================================================================================\n",
            "Tokenizer sanity: has None in input_ids? -> False\n",
            "Tokenizer decode sanity: OK\n",
            "================================================================================\n"
          ]
        }
      ],
      "execution_count": 74,
      "source": [
        "import torch, platform, re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "from typing import Union, List, Dict, Any\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "MODEL_ID = \"skt/kogpt2-base-v2\"\n",
        "CKPT_DIR = \"outputs/seller_reply_lora\"\n",
        "\n",
        "# =========================\n",
        "# Device picker\n",
        "# =========================\n",
        "def pick_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    if platform.system() == \"Darwin\" and torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    return \"cpu\"\n",
        "\n",
        "device = pick_device()\n",
        "print(\"device =\", device)\n",
        "\n",
        "# =========================\n",
        "# 1) ✅ Tokenizer: 베이스 모델에서 로드 (fast 사용)\n",
        "# =========================\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "except Exception as e:\n",
        "    print(\"AutoTokenizer(use_fast=True) failed ->\", repr(e))\n",
        "    raise\n",
        "\n",
        "print(\"tokenizer class =\", tokenizer.__class__.__name__)\n",
        "\n",
        "# (안전) eos/pad 보장\n",
        "if tokenizer.eos_token is None:\n",
        "    tokenizer.eos_token = \"<|endoftext|>\"\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
        "\n",
        "print(\"len(tokenizer) =\", len(tokenizer))\n",
        "print(\"bos:\", tokenizer.bos_token_id, \"eos:\", tokenizer.eos_token_id, \"pad:\", tokenizer.pad_token_id)\n",
        "\n",
        "# =========================\n",
        "# 2) Base model load\n",
        "# =========================\n",
        "base_model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
        "\n",
        "# tokenizer 길이에 맞춰 임베딩 리사이즈 (pad 추가했으면 +1 됨)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "base_model.config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# =========================\n",
        "# 3) Load LoRA adapter\n",
        "# =========================\n",
        "model = PeftModel.from_pretrained(base_model, CKPT_DIR)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"emb size       =\", model.get_input_embeddings().weight.shape[0])\n",
        "print(\"vocab==emb ?   =\", len(tokenizer) == model.get_input_embeddings().weight.shape[0])\n",
        "\n",
        "# ============================================================\n",
        "# Debugging block A: tokenizer sanity\n",
        "# ============================================================\n",
        "print(\"=\" * 80)\n",
        "test_text = \"리뷰: 배송이 늦어요\\n판매자 답변:\"\n",
        "enc = tokenizer(test_text, add_special_tokens=True)\n",
        "has_none = any(x is None for x in enc[\"input_ids\"])\n",
        "print(\"Tokenizer sanity: has None in input_ids? ->\", has_none)\n",
        "\n",
        "try:\n",
        "    _ = tokenizer.decode(enc[\"input_ids\"], skip_special_tokens=False)\n",
        "    print(\"Tokenizer decode sanity: OK\")\n",
        "except Exception as e:\n",
        "    print(\"Tokenizer decode sanity: FAIL ->\", repr(e))\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================\n",
        "# 4) generate_reply (간단/안정형)\n",
        "# ============================================================\n",
        "def _dedup_sentences_ko(text: str, max_sent: int = 4) -> str:\n",
        "    # 문장 중복 제거(마침표/줄바꿈 기준)\n",
        "    parts = re.split(r'(?<=[.!?])\\s+|\\n+', text.strip())\n",
        "    seen = []\n",
        "    for p in parts:\n",
        "        p = p.strip()\n",
        "        if not p:\n",
        "            continue\n",
        "        if p not in seen:\n",
        "            seen.append(p)\n",
        "        if len(seen) >= max_sent:\n",
        "            break\n",
        "    return \" \".join(seen)\n",
        "\n",
        "def generate_reply(prompt, max_new_tokens=96, **gen_kwargs):\n",
        "    prompt = str(prompt)\n",
        "\n",
        "    max_len = int(getattr(model.config, \"n_positions\", 1024) or 1024)\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        add_special_tokens=True,\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "    # ✅ 규칙/헤더가 답변으로 나오지 않게 금지 토큰 설정\n",
        "    banned = [\"### 역할\", \"### 규칙\", \"### 고객 리뷰\", \"규칙:\", \"\\n- \"]\n",
        "    bad_words_ids = [tokenizer(b, add_special_tokens=False).input_ids for b in banned]\n",
        "\n",
        "    # ✅ 반복 억제 기본값 (필요시 여기만 미세 조정)\n",
        "    defaults = dict(\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        top_k=50,\n",
        "        repetition_penalty=1.15,\n",
        "        no_repeat_ngram_size=4,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        bad_words_ids=bad_words_ids,\n",
        "    )\n",
        "    defaults.update(gen_kwargs)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(**inputs, max_new_tokens=max_new_tokens, **defaults)\n",
        "\n",
        "    # ✅ “생성된 부분만” 디코딩\n",
        "    gen_ids = out[0, input_len:]\n",
        "    text = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    # ✅ 혹시 남아있는 헤더/리스트 라인 제거(안전망)\n",
        "    lines = []\n",
        "    for line in text.splitlines():\n",
        "        s = line.strip()\n",
        "        if not s:\n",
        "            continue\n",
        "        if s.startswith(\"###\") or s.startswith(\"-\") or s.startswith(\"규칙:\") or s.startswith(\"리뷰:\"):\n",
        "            continue\n",
        "        lines.append(s)\n",
        "    text = \" \".join(lines).strip()\n",
        "\n",
        "    # ✅ 문장 반복 제거 + 2~4문장 컷\n",
        "    text = _dedup_sentences_ko(text, max_sent=4)\n",
        "\n",
        "    return text"
      ],
      "id": "7ff2c89fbd72024e"
    },
    {
      "metadata": {
        "id": "73f5a67bde84e9d8"
      },
      "cell_type": "markdown",
      "source": [
        "10. 프롬프트 3종 비교(단순/조건/강한 제약)"
      ],
      "id": "73f5a67bde84e9d8"
    },
    {
      "metadata": {
        "id": "b80027d34b35cc89",
        "ExecuteTime": {
          "end_time": "2025-12-31T05:37:01.956562Z",
          "start_time": "2025-12-31T05:37:01.707017Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5687d7d6-ab0e-413c-9d8e-b120880bbe4f"
      },
      "cell_type": "code",
      "source": [
        "# 프롬프트는 여기에 입력해주세요\n",
        "# 리뷰는 여기에 작성\n",
        "sample_review_neg = \"배송도 느리고 품질도 별로에요. 사지 마세요.\"\n",
        "sample_review_pos = \"너무너무 최고입니다\"\n",
        "\n",
        "# 여기서 프롬프트 변경\n",
        "def prompt_basic(review) -> str:\n",
        "    return f\"리뷰: {review}\\n판매자 답변:\"\n",
        "\n",
        "def prompt_with_rules(review) -> str:\n",
        "    rules = (\n",
        "        \"규칙: 한국어 존댓말, 2~4문장.\\n\"\n",
        "        +\"부정일 경우 사과+해결책+보상(쿠폰/교환/환불 중 하나)을 반드시 포함.\\n\"\n",
        "        +\"긍정일 경우 감사+재구매 유도 포함.\\n\"\n",
        "    )\n",
        "    return f\"{rules}리뷰: {review}\\n판매자 답변:\"\n",
        "\n",
        "def prompt_project_style(review: str) -> str:\n",
        "    return (\n",
        "        \"당신은 쇼핑몰 판매자입니다.\\n\"\n",
        "        \"반드시 아래 분류에 맞는 답변만 작성하세요.\\n\"\n",
        "        \"분류: 이 리뷰는 '부정'입니다. (긍정 답변 금지)\\n\"\n",
        "        \"규칙: 존댓말, 2~4문장, 사과+해결책+보상(쿠폰/교환/환불 중 하나).\\n\"\n",
        "        f\"리뷰: {review}\\n\"\n",
        "        \"판매자 답변:\"\n",
        "    )\n",
        "\n",
        "for p in [\n",
        "    prompt_basic(sample_review_neg),\n",
        "    prompt_with_rules(sample_review_neg),\n",
        "    prompt_project_style(sample_review_neg),\n",
        "]:\n",
        "    print(\"PROMPT:\\n\", p)\n",
        "    print(\"OUTPUT:\\n\", generate_reply(p, max_new_tokens=80))\n",
        "    print(\"=\"*80)\n",
        "\n",
        "for p in [\n",
        "    prompt_basic(sample_review_pos),\n",
        "    prompt_with_rules(sample_review_pos),\n",
        "    prompt_project_style(sample_review_pos),\n",
        "]:\n",
        "    print(\"PROMPT:\\n\", p)\n",
        "    print(\"OUTPUT:\\n\", generate_reply(p, max_new_tokens=80))\n",
        "    print(\"=\"*80)\n"
      ],
      "id": "b80027d34b35cc89",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT:\n",
            " 리뷰: 배송도 느리고 품질도 별로에요. 사지 마세요.\n",
            "판매자 답변:\n",
            "OUTPUT:\n",
            " 당신은 온라인 쇼핑몰 판매자입니다. 안녕하세요, 고객님. 소중한 후기 감사합니다. 앞으로 더 좋은 상품과 서비스로 보답하겠습니다.\n",
            "================================================================================\n",
            "PROMPT:\n",
            " 규칙: 한국어 존댓말, 2~4문장.\n",
            "부정일 경우 사과+해결책+보상(쿠폰/교환/환불 중 하나)을 반드시 포함.\n",
            "긍정일 경우 감사+재구매 유도 포함.\n",
            "리뷰: 배송도 느리고 품질도 별로에요. 사지 마세요.\n",
            "판매자 답변:\n",
            "OUTPUT:\n",
            " 만족스러웠는데 포장상에서는 괜찮은 것 같습니다. 재구매 시 추가 비용이나 문제점은 없으시죠? 안녕하세요, 고객님. 불편을 드려 진심으로 죄송합니다.\n",
            "================================================================================\n",
            "PROMPT:\n",
            " 당신은 쇼핑몰 판매자입니다.\n",
            "반드시 아래 분류에 맞는 답변만 작성하세요.\n",
            "분류: 이 리뷰는 '부정'입니다. (긍정 답변 금지)\n",
            "규칙: 존댓말, 2~4문장, 사과+해결책+보상(쿠폰/교환/환불 중 하나).\n",
            "리뷰: 배송도 느리고 품질도 별로에요. 사지 마세요.\n",
            "판매자 답변:\n",
            "OUTPUT:\n",
            " 만족합니다. 고객님께 죄송합니다. 주문 정보와 문제 상황을 확인할 수 있도록 문의 남겨주시면 빠르게 도와드리겠습니다. 교환/환불을 도와드리겠습니다.\n",
            "================================================================================\n",
            "PROMPT:\n",
            " 리뷰: 너무너무 최고입니다\n",
            "판매자 답변:\n",
            "OUTPUT:\n",
            " \n",
            "================================================================================\n",
            "PROMPT:\n",
            " 규칙: 한국어 존댓말, 2~4문장.\n",
            "부정일 경우 사과+해결책+보상(쿠폰/교환/환불 중 하나)을 반드시 포함.\n",
            "긍정일 경우 감사+재구매 유도 포함.\n",
            "리뷰: 너무너무 최고입니다\n",
            "판매자 답변:\n",
            "OUTPUT:\n",
            " 배송 중에 있어요~~ 안녕하세요, 고객님. 배송 관련하여 만족해 주셔서 정말 기쁩니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 소중한 후기 감사합니다.\n",
            "================================================================================\n",
            "PROMPT:\n",
            " 당신은 쇼핑몰 판매자입니다.\n",
            "반드시 아래 분류에 맞는 답변만 작성하세요.\n",
            "분류: 이 리뷰는 '부정'입니다. (긍정 답변 금지)\n",
            "규칙: 존댓말, 2~4문장, 사과+해결책+보상(쿠폰/교환/환불 중 하나).\n",
            "리뷰: 너무너무 최고입니다\n",
            "판매자 답변:\n",
            "OUTPUT:\n",
            " 재구매할려고 하네요 안녕하세요, 고객님. 소중한 후기 감사합니다. 앞으로도 더 좋은 상품과 서비스로 보답하겠습니다. 다음에도 만족스러운 경험을 드리겠습니다.\n",
            "================================================================================\n"
          ]
        }
      ],
      "execution_count": 81
    },
    {
      "metadata": {
        "id": "21de0f2b77feaf54"
      },
      "cell_type": "markdown",
      "source": [
        "11. 규칙 준수 점수(간단 룰 기반)"
      ],
      "id": "21de0f2b77feaf54"
    },
    {
      "metadata": {
        "id": "796300a9b1260e83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e344ecf-fd0a-425f-c4b1-88555f657029"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg rule score: 1.34\n"
          ]
        }
      ],
      "execution_count": 62,
      "source": [
        "import re\n",
        "\n",
        "def score_reply(review_rating, reply):\n",
        "    score = 0\n",
        "    # 문장 수(대충 .?! 기준)\n",
        "    sentences = [s for s in re.split(r\"[.?!]\\s*\", reply) if s.strip()]\n",
        "    if 2 <= len(sentences) <= 4:\n",
        "        score += 1\n",
        "\n",
        "    if review_rating <= 2:\n",
        "        if any(k in reply for k in [\"죄송\", \"사과\"]):\n",
        "            score += 1\n",
        "        if any(k in reply for k in [\"교환\", \"환불\", \"쿠폰\", \"보상\"]):\n",
        "            score += 1\n",
        "    if review_rating >= 4:\n",
        "        if any(k in reply for k in [\"감사\", \"고맙\"]):\n",
        "            score += 1\n",
        "        if any(k in reply for k in [\"재구매\", \"다음에도\", \"또 이용\"]):\n",
        "            score += 1\n",
        "    return score\n",
        "\n",
        "# 샘플 50개로 점수 보기\n",
        "samples = random.sample(filtered, 50)\n",
        "total = 0\n",
        "for r, review in samples:\n",
        "    p = prompt_project_style(review)\n",
        "    out = generate_reply(p)\n",
        "    total += score_reply(r, out)\n",
        "\n",
        "print(\"avg rule score:\", total/50)\n"
      ],
      "id": "796300a9b1260e83"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "final_exam",
      "language": "python",
      "name": "final_exam"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00a8b8a2264c4e95a3a471fbce39c342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4383e05429fb4761bc32c999f43cfcbc",
              "IPY_MODEL_a6e85e24d92e4854a4d216b0883b1a67",
              "IPY_MODEL_43404553c17642ac8e4ecb021e5b036c"
            ],
            "layout": "IPY_MODEL_6e2d646905274e4f8058af2ef6ae3a4d"
          }
        },
        "4383e05429fb4761bc32c999f43cfcbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7695998435804ea5922e157bb4ed2339",
            "placeholder": "​",
            "style": "IPY_MODEL_161e7732a7be4a968cc8522ce51420b0",
            "value": "Map: 100%"
          }
        },
        "a6e85e24d92e4854a4d216b0883b1a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f46f2930a464c2dbb7b0d243713f880",
            "max": 19000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_838b233270af40f6b3153c8f4a7cb256",
            "value": 19000
          }
        },
        "43404553c17642ac8e4ecb021e5b036c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7369d46ebdff4efb91d3a8f053babf00",
            "placeholder": "​",
            "style": "IPY_MODEL_f5a646804d7e444d9dc931651375e22e",
            "value": " 19000/19000 [00:12&lt;00:00, 1416.23 examples/s]"
          }
        },
        "6e2d646905274e4f8058af2ef6ae3a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7695998435804ea5922e157bb4ed2339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "161e7732a7be4a968cc8522ce51420b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f46f2930a464c2dbb7b0d243713f880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838b233270af40f6b3153c8f4a7cb256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7369d46ebdff4efb91d3a8f053babf00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a646804d7e444d9dc931651375e22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0da72e48fc9045abb1dea76c4135c8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d91100e7f8a49ffb1089958dd3dbecc",
              "IPY_MODEL_e4cdd7a39ef14facac769658323a6121",
              "IPY_MODEL_5ec0211749b141ec881aa6c5095d65ef"
            ],
            "layout": "IPY_MODEL_f1c18db8d79a48feb830c944a93517db"
          }
        },
        "7d91100e7f8a49ffb1089958dd3dbecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6df4483f0f7f4e369b2264eb6d78e22a",
            "placeholder": "​",
            "style": "IPY_MODEL_a49e868014d74b04b60ee1369ea1ac32",
            "value": "Map: 100%"
          }
        },
        "e4cdd7a39ef14facac769658323a6121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4f7e6b576d4ea89285a5ffd9ae33b6",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa88d917669040fa9076483bec21f9f5",
            "value": 1000
          }
        },
        "5ec0211749b141ec881aa6c5095d65ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e21caac0e14abaa156363da896b21a",
            "placeholder": "​",
            "style": "IPY_MODEL_b4bb8b5ff6354ad796fd1a53196ef700",
            "value": " 1000/1000 [00:00&lt;00:00, 2451.42 examples/s]"
          }
        },
        "f1c18db8d79a48feb830c944a93517db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df4483f0f7f4e369b2264eb6d78e22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49e868014d74b04b60ee1369ea1ac32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de4f7e6b576d4ea89285a5ffd9ae33b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa88d917669040fa9076483bec21f9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53e21caac0e14abaa156363da896b21a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bb8b5ff6354ad796fd1a53196ef700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}